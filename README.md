保存一些自己看过的论文

### 火控相关(中文)
知网上的中文论文，涉及火控、威胁评估、制导律、多机协同等

### 强化学习
#### model-free
DQN: [Human-level control through deep reinforcement learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Human-level%20control%20through%20deep%20reinforcement%20learning(Nature).pdf)  
     [Playing Atari with Deep Reinforcement Learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning(ICML).pdf)  
DPG: [Deterministic policy gradient algorithms](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Deterministic%20policy%20gradient%20algorithms.pdf)  
DDPG: [Continuous control with deep reinforcement learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Continuous%20control%20with%20deep%20reinforcement%20learning.pdf)  
PG: [Policy Gradient Methods for Reinforcement Learning with Function Approximation](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Policy%20Gradient%20Methods%20for%20Reinforcement%20Learning%20with%20Function%20Approximation.pdf)  
A3C: [Asynchronous methods for deep reinforcement learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Asynchronous%20methods%20for%20deep%20reinforcement%20learning.pdf)  
TRPO: [Approximately optimal approximate reinforcement learning(前序工作)](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Approximately%20optimal%20approximate%20reinforcement%20learning.pdf)  
      [Trust region policy optimization](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Trust%20region%20policy%20optimization.pdf)  
PPO: [Proximal policy optimization algorithms](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/model-free/Proximal%20policy%20optimization%20algorithms.pdf)  

#### hierachical reinforcement learning
Option: [Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Between%20MDPs%20and%20semi-MDPs:%0AA%20framework%20for%20temporal%20abstraction%0Ain%20reinforcement%20learning.pdf)  
OC: [The Option-Critic Architecture](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/The%20Option-Critic%20Architecture.pdf)    
A2OC: [When Waiting is not an Option  Learning Options with a Deliberation Cost](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/When%20Waiting%20is%20not%20an%20Option%20%20Learning%20Options%20with%20a%20Deliberation%20Cost.pdf)  
Feudal: [Feudal Reinforcement Learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Feudal%20Reinforcement%20Learning.pdf)  
FuNs: [FeUdal Networks for Hierarchical Reinforcement Learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/FeUdal%20Networks%20for%20Hierarchical%20Reinforcement%20Learning.pdf)  
h-DQN: [Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Hierarchical%20Deep%20Reinforcement%20Learning:%0AIntegrating%20Temporal%20Abstraction%20and%0AIntrinsic%20Motivation.pdf)  
HAM: [Reinforcement Learning with Hierarchies of Machines](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Reinforcement%20Learning%20with%20Hierarchies%20of%20Machines.pdf)  
MAXQ: [The MAXQ Method for Hierarchical Reinforcement Learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/The%20MAXQ%20Method%20for%20Hierarchical%20Reinforcement%20Learning.pdf)  
UVFA: [Universal Value Function Approximators](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Universal%20Value%20Function%20Approximators.pdf)  
HER: [Hindsight Experience Replay](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Hindsight%20Experience%20Replay.pdf) 
HAC: [Learning Multi-Level Hierachies with Hindsight](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Learning%20Multi-Level%20Hierachies%20with%20Hindsight.pdf)   
HIRO: [Data-Efficient Hierarchical Reinforcement Learning](https://gitee.com/yangshengqi/paper/blob/master/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/hierachical%20reinforcement%20learning/Data-Efficient%20Hierarchical%20Reinforcement%20Learning.pdf)  
 

  
